{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9173807",
   "metadata": {},
   "source": [
    "# Extracci√≥n de Datos de Fondos de Inversi√≥n - Santander\n",
    "\n",
    "Este notebook automatiza la extracci√≥n de datos de composici√≥n de carteras de fondos de inversi√≥n desde los reportes mensuales CAFCI de Santander Argentina.\n",
    "\n",
    "## Flujo del proceso:\n",
    "1. **Instalaci√≥n de dependencias**\n",
    "2. **Importaci√≥n de librer√≠as**\n",
    "3. **Configuraci√≥n de par√°metros**\n",
    "4. **Navegaci√≥n web automatizada** (Selenium)\n",
    "5. **Descarga y extracci√≥n de datos del PDF**\n",
    "6. **Procesamiento y transformaci√≥n de datos**\n",
    "7. **Almacenamiento en Data Warehouse**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47862aa-f770-4ab3-adc3-db4dbd4dfd0a",
   "metadata": {},
   "source": [
    "## 1. Instalaci√≥n de Dependencias\n",
    "\n",
    "Instalamos las bibliotecas necesarias para el web scraping, procesamiento de PDFs y manipulaci√≥n de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489d0bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install selenium pandas requests pypdf PyMuPDF python-dateutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e631b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reiniciar kernel despu√©s de instalar paquetes (solo necesario en Databricks)\n",
    "try:\n",
    "    dbutils.library.restartPython()\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è No se ejecut√≥ dbutils.library.restartPython() (no est√°s en Databricks)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6f944e",
   "metadata": {},
   "source": [
    "## 2. Importaci√≥n de Librer√≠as\n",
    "\n",
    "Importamos todas las bibliotecas necesarias para el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb2d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import locale\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import io\n",
    "import re\n",
    "from pypdf import PdfReader \n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "from typing import Optional, Tuple\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Suprimir warnings espec√≠ficos de PyMuPDF\n",
    "import logging\n",
    "logging.getLogger('fitz').setLevel(logging.ERROR)\n",
    "\n",
    "@contextmanager\n",
    "def timeout_context(seconds):\n",
    "    import threading\n",
    "    def timeout_handler():\n",
    "        raise TimeoutError(f\"Operaci√≥n excedi√≥ el l√≠mite de {seconds} segundos\")\n",
    "    timer = threading.Timer(seconds, timeout_handler)\n",
    "    timer.start()\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        timer.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc6f5ad",
   "metadata": {},
   "source": [
    "## 3. Configuraci√≥n de Par√°metros\n",
    "\n",
    "Definimos las constantes y configuraciones del proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeef569",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    URL_FONDO = \"https://www.santander.com.ar/empresas/inversiones/informacion-fondos#/detail/12\"\n",
    "    XPATH_REPORTE = \"//a[contains(., 'Reporte mensual - CAFCI')]\"\n",
    "    SELENIUM_REMOTE_URL = \"https://standalone-chrome-production-c170.up.railway.app/wd/hub\"\n",
    "    USE_REMOTE_CHROME = True\n",
    "    N_FILAS_ESPERADAS = 10\n",
    "    TABLA_AREA = [380, 300, 640, 770]\n",
    "    SOCIEDAD_GERENTE = \"Santander AM\"\n",
    "    NOMBRE_FONDO_DEFAULT = \"Superfondo Renta Variable - Clase A\"\n",
    "    PATTERN_NOMBRE = re.compile(r'Superfondo\\s+(.*?)\\s*-\\s*Clase\\s+\\w', re.IGNORECASE | re.DOTALL)\n",
    "    PATTERN_FECHA = re.compile(r'Datos\\s*al\\s*(\\d{1,2}.*?\\d{4})', re.IGNORECASE | re.DOTALL)\n",
    "    TIMEOUT_IMPLICIT = 10\n",
    "    TIMEOUT_EXPLICIT = 10\n",
    "    TABLA_ALMACENAMIENTO = \"datos_semanales_bancos\"\n",
    "\n",
    "def configurar_locale():\n",
    "    locales_spanish = ['es_ES.UTF-8', 'Spanish_Spain', 'es']\n",
    "    for loc in locales_spanish:\n",
    "        try:\n",
    "            locale.setlocale(locale.LC_TIME, loc)\n",
    "            return True\n",
    "        except locale.Error:\n",
    "            continue\n",
    "    return False\n",
    "\n",
    "configurar_locale()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547643dd",
   "metadata": {},
   "source": [
    "## 4. Funciones de Utilidad\n",
    "\n",
    "Definimos funciones reutilizables para cada etapa del proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db4e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_driver() -> webdriver.Chrome:\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    \n",
    "    try:\n",
    "        print(f\"üåê Conectando a Chrome remoto (Railway): {Config.SELENIUM_REMOTE_URL}\")\n",
    "        driver = webdriver.Remote(\n",
    "            command_executor=Config.SELENIUM_REMOTE_URL,\n",
    "            options=chrome_options\n",
    "        )\n",
    "        driver.implicitly_wait(Config.TIMEOUT_IMPLICIT)\n",
    "        print(\"‚úÖ Conectado exitosamente a Railway\")\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error conectando a Chrome remoto: {str(e)[:500]}\")\n",
    "        raise RuntimeError(\"No se pudo conectar al Chrome remoto de Railway.\")\n",
    "\n",
    "\n",
    "def obtener_url_pdf(url: str, xpath: str) -> Optional[str]:\n",
    "    driver = None\n",
    "    try:\n",
    "        driver = obtener_driver()\n",
    "        driver.set_page_load_timeout(30)\n",
    "        driver.set_script_timeout(30)\n",
    "        \n",
    "        ventana_original = driver.current_window_handle\n",
    "        \n",
    "        print(f\"üåê Navegando a {url}\")\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        wait = WebDriverWait(driver, 15)\n",
    "        enlace = wait.until(EC.presence_of_element_located((By.XPATH, xpath)))\n",
    "        \n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", enlace)\n",
    "        time.sleep(0.5)\n",
    "        driver.execute_script(\"arguments[0].click();\", enlace)\n",
    "        \n",
    "        wait.until(EC.number_of_windows_to_be(2))\n",
    "        \n",
    "        for ventana in driver.window_handles:\n",
    "            if ventana != ventana_original:\n",
    "                driver.switch_to.window(ventana)\n",
    "                break\n",
    "        \n",
    "        time.sleep(1)\n",
    "        pdf_url = driver.current_url\n",
    "        \n",
    "        if pdf_url and pdf_url.endswith(\".pdf\"):\n",
    "            print(f\"‚úÖ PDF encontrado\")\n",
    "            return pdf_url\n",
    "        else:\n",
    "            print(\"‚ùå URL no termina en .pdf\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en navegaci√≥n: {e}\")\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        if driver:\n",
    "            try:\n",
    "                driver.quit()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "def descargar_pdf(url: str) -> Optional[io.BytesIO]:\n",
    "    try:\n",
    "        print(\"üì• Descargando PDF...\")\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        pdf_file = io.BytesIO(response.content)\n",
    "        print(f\"‚úÖ Descargado ({len(response.content):,} bytes)\")\n",
    "        return pdf_file\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error descargando PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extraer_texto_pdf(pdf_file: io.BytesIO) -> str:\n",
    "    try:\n",
    "        pdf_file.seek(0)\n",
    "        reader = PdfReader(pdf_file)\n",
    "        return reader.pages[0].extract_text()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error extrayendo texto: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def extraer_nombre_fondo(texto: str) -> str:\n",
    "    match = Config.PATTERN_NOMBRE.search(texto)\n",
    "    if match:\n",
    "        nombre = f\"Superfondo {match.group(1).strip()} - Clase A\"\n",
    "        print(f\"‚úÖ Fondo: {nombre}\")\n",
    "        return nombre\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Nombre no encontrado. Usando default\")\n",
    "        return Config.NOMBRE_FONDO_DEFAULT\n",
    "\n",
    "\n",
    "def extraer_fecha(texto: str) -> Tuple[Optional[datetime], str]:\n",
    "    from dateutil import parser as dateutil_parser\n",
    "    \n",
    "    match = Config.PATTERN_FECHA.search(texto)\n",
    "    if not match:\n",
    "        print(\"‚ùå Fecha no encontrada en el PDF\")\n",
    "        return None, \"Fecha no encontrada\"\n",
    "    \n",
    "    fecha_str = re.sub(r'\\s+', ' ', match.group(1).strip())\n",
    "    print(f\"   Debug: fecha_str extra√≠da = '{fecha_str}'\")\n",
    "    \n",
    "    # Mapeo de meses en espa√±ol a n√∫mero\n",
    "    meses_es = {\n",
    "        'enero': '01', 'febrero': '02', 'marzo': '03', 'abril': '04',\n",
    "        'mayo': '05', 'junio': '06', 'julio': '07', 'agosto': '08',\n",
    "        'septiembre': '09', 'octubre': '10', 'noviembre': '11', 'diciembre': '12'\n",
    "    }\n",
    "    \n",
    "    # Intentar parsear manualmente si contiene meses en espa√±ol\n",
    "    fecha_lower = fecha_str.lower()\n",
    "    print(f\"   Debug: fecha_lower = '{fecha_lower}'\")\n",
    "    \n",
    "    for mes_nombre, mes_num in meses_es.items():\n",
    "        if mes_nombre in fecha_lower:\n",
    "            print(f\"   Debug: Encontrado mes '{mes_nombre}'\")\n",
    "            try:\n",
    "                # Extraer d√≠a y a√±o - usando regex flexible para \"de\" entre d√≠a y mes\n",
    "                regex_pattern = r'(\\d{1,2})\\s+(?:de\\s+)?' + mes_nombre + r'(?:\\s+de)?\\s+(\\d{4})'\n",
    "                print(f\"   Debug: Intentando regex: {regex_pattern}\")\n",
    "                match_dia_anio = re.search(regex_pattern, fecha_lower)\n",
    "                if match_dia_anio:\n",
    "                    dia = match_dia_anio.group(1).zfill(2)\n",
    "                    anio = match_dia_anio.group(2)\n",
    "                    # Construir fecha en formato ISO YYYY-MM-DD (m√°s robusto)\n",
    "                    fecha_formato = f\"{anio}-{mes_num}-{dia}\"\n",
    "                    print(f\"   Debug: fecha_formato = '{fecha_formato}'\")\n",
    "                    # Usar datetime.strptime que es m√°s robusto que pd.to_datetime en Databricks\n",
    "                    from datetime import datetime as dt\n",
    "                    fecha_dt = dt.strptime(fecha_formato, \"%Y-%m-%d\")\n",
    "                    print(f\"‚úÖ Fecha parseada: {fecha_dt.strftime('%Y-%m-%d')}\")\n",
    "                    return fecha_dt, fecha_str\n",
    "                else:\n",
    "                    print(f\"   Debug: Regex no coincidi√≥ para mes {mes_nombre}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   Debug: Error parsing con mes {mes_nombre}: {e}\")\n",
    "                pass\n",
    "    \n",
    "    print(f\"   Debug: No se encontr√≥ ning√∫n mes en espa√±ol\")\n",
    "    \n",
    "    # Si no tiene meses en espa√±ol, intentar con dateutil (m√°s flexible)\n",
    "    try:\n",
    "        # dateutil.parser es muy robusto y maneja muchos formatos\n",
    "        fecha_dt = dateutil_parser.parse(fecha_str, dayfirst=True)\n",
    "        print(f\"‚úÖ Fecha parseada con dateutil: {fecha_dt.strftime('%Y-%m-%d')}\")\n",
    "        return fecha_dt, fecha_str\n",
    "    except Exception as e:\n",
    "        print(f\"   Debug: dateutil tambi√©n fall√≥: {e}\")\n",
    "    \n",
    "    # √öltimo intento: formatos est√°ndar\n",
    "    formatos = [\"%d de %B %Y\", \"%d de %B de %Y\", \"%d/%m/%Y\", \"%d-%m-%Y\"]\n",
    "    for formato in formatos:\n",
    "        try:\n",
    "            fecha_dt = pd.to_datetime(fecha_str, format=formato)\n",
    "            print(f\"‚úÖ Fecha parseada: {fecha_dt.strftime('%Y-%m-%d')}\")\n",
    "            return fecha_dt, fecha_str\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    print(f\"‚ùå No se pudo parsear la fecha: '{fecha_str}'\")\n",
    "    return None, fecha_str\n",
    "\n",
    "\n",
    "def extraer_valor_cuota_parte(pdf_file: io.BytesIO) -> float:\n",
    "    try:\n",
    "        pdf_file.seek(0)\n",
    "        doc = fitz.open(stream=pdf_file.read(), filetype=\"pdf\")\n",
    "        page = doc[0]\n",
    "        \n",
    "        # Extraer todo el texto\n",
    "        texto = page.get_text()\n",
    "        \n",
    "        # Buscar patr√≥n de valor de cuotaparte\n",
    "        match = re.search(r'Valor de cuotaparte.*?\\$\\)\\s*([\\d.]+[,][\\d]+)', texto, re.IGNORECASE | re.DOTALL)\n",
    "        if match:\n",
    "            valor_str = match.group(1).strip().replace('.', '').replace(',', '.')\n",
    "            valor = float(valor_str)\n",
    "            print(f\"‚úÖ Valor cuota parte: ${valor:,.2f}\")\n",
    "            doc.close()\n",
    "            return valor\n",
    "        \n",
    "        doc.close()\n",
    "        print(f\"‚ö†Ô∏è Valor cuota parte no encontrado. Usando default: 1.0\")\n",
    "        return 1.0\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error extrayendo valor cuota parte: {e}. Usando 1.0\")\n",
    "        return 1.0\n",
    "\n",
    "\n",
    "def extraer_perfil_riesgo(pdf_file: io.BytesIO) -> str:\n",
    "    try:\n",
    "        pdf_file.seek(0)\n",
    "        doc = fitz.open(stream=pdf_file.read(), filetype=\"pdf\")\n",
    "        page = doc[0]\n",
    "        \n",
    "        # Extraer todo el texto\n",
    "        texto = page.get_text()\n",
    "        \n",
    "        # Buscar patr√≥n de perfil de riesgo\n",
    "        match = re.search(r'Perfil de riesgo\\s+(\\w+)', texto, re.IGNORECASE)\n",
    "        if match:\n",
    "            perfil = match.group(1).strip()\n",
    "            print(f\"‚úÖ Perfil de riesgo: {perfil}\")\n",
    "            doc.close()\n",
    "            return perfil\n",
    "        \n",
    "        doc.close()\n",
    "        print(f\"‚ö†Ô∏è Perfil de riesgo no encontrado. Usando default: Alto\")\n",
    "        return 'Alto'\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error extrayendo perfil riesgo: {e}. Usando Alto\")\n",
    "        return 'Alto'\n",
    "\n",
    "\n",
    "def extraer_tabla_composicion_v2(pdf_file: io.BytesIO, n_filas: int = 10) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Extrae la composici√≥n de la cartera (acciones individuales) del PDF usando PyMuPDF.\n",
    "    \n",
    "    Estrategia:\n",
    "    1. Busca porcentajes en el √°rea derecha (x > 480)\n",
    "    2. Para cada porcentaje, busca la l√≠nea completa de texto en la misma Y\n",
    "    3. Extrae acci√≥n completa (nombre + ticker) de esa l√≠nea\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pdf_file.seek(0)\n",
    "        doc = fitz.open(stream=pdf_file.read(), filetype=\"pdf\")\n",
    "        page = doc[0]\n",
    "        \n",
    "        # Extraer palabras con posiciones\n",
    "        words = page.get_text(\"words\")  # [(x0, y0, x1, y1, \"word\", block_no, line_no, word_no)]\n",
    "        \n",
    "        if not words:\n",
    "            print(\"‚ùå No se pudieron extraer palabras del PDF\")\n",
    "            doc.close()\n",
    "            return None\n",
    "        \n",
    "        print(\"üìÑ Extrayendo composici√≥n de acciones del PDF con PyMuPDF...\")\n",
    "        \n",
    "        # PASO 1: Buscar porcentajes en √°rea derecha (x > 480, y: 420-580)\n",
    "        porcentajes_encontrados = []\n",
    "        for w in words:\n",
    "            x0, y0, x1, y1, text, *_ = w\n",
    "            if x0 > 480 and 420 < y0 < 580:\n",
    "                text_clean = text.strip().replace('%', '')\n",
    "                if text_clean.isdigit() and 1 <= int(text_clean) <= 99:\n",
    "                    porcentajes_encontrados.append({\n",
    "                        'pct': int(text_clean),\n",
    "                        'y': y0,\n",
    "                        'x': x0\n",
    "                    })\n",
    "        \n",
    "        porcentajes_encontrados.sort(key=lambda x: x['y'])\n",
    "        \n",
    "        print(f\"   Porcentajes encontrados: {len(porcentajes_encontrados)}\")\n",
    "        \n",
    "        if not porcentajes_encontrados:\n",
    "            print(\"‚ùå No se encontraron porcentajes en el √°rea esperada\")\n",
    "            doc.close()\n",
    "            return None\n",
    "        \n",
    "        # PASO 2: Extraer l√≠neas completas de texto con get_text(\"dict\")\n",
    "        text_dict = page.get_text(\"dict\")\n",
    "        lineas_completas = []\n",
    "        \n",
    "        for block in text_dict['blocks']:\n",
    "            if 'lines' in block:\n",
    "                for line in block['lines']:\n",
    "                    # Unir todos los spans de una l√≠nea\n",
    "                    line_text = \"\"\n",
    "                    line_y = None\n",
    "                    line_x0 = 999999\n",
    "                    \n",
    "                    for span in line['spans']:\n",
    "                        bbox = span['bbox']\n",
    "                        y = bbox[1]\n",
    "                        x = bbox[0]\n",
    "                        \n",
    "                        # √Årea de composici√≥n: nombres de acciones est√°n entre x: 300-450\n",
    "                        if 420 < y < 580 and 300 < x < 460:\n",
    "                            line_text += span['text']\n",
    "                            if line_y is None:\n",
    "                                line_y = y\n",
    "                            line_x0 = min(line_x0, x)\n",
    "                    \n",
    "                    if line_text.strip() and line_y:\n",
    "                        # Filtrar l√≠neas que sean solo n√∫meros o porcentajes\n",
    "                        texto = line_text.strip()\n",
    "                        # Ignorar si es solo n√∫meros (4000, 2000, etc.)\n",
    "                        if texto.isdigit():\n",
    "                            continue\n",
    "                        # Ignorar si es solo porcentaje (40%, 60%, etc.)\n",
    "                        if texto.replace('%', '').strip().isdigit():\n",
    "                            continue\n",
    "                        # Ignorar l√≠neas muy cortas (menos de 3 caracteres)\n",
    "                        if len(texto) < 3:\n",
    "                            continue\n",
    "                        \n",
    "                        lineas_completas.append({\n",
    "                            'texto': texto,\n",
    "                            'y': line_y,\n",
    "                            'x': line_x0\n",
    "                        })\n",
    "        \n",
    "        lineas_completas.sort(key=lambda x: x['y'])\n",
    "        \n",
    "        # PASO 3: MAPEO - Unir porcentajes con l√≠neas completas por posici√≥n Y\n",
    "        composicion = []\n",
    "        tolerancia_y = 5  # Tolerancia de 5 puntos en coordenada Y\n",
    "        \n",
    "        for pct_data in porcentajes_encontrados:\n",
    "            pct_y = pct_data['y']\n",
    "            porcentaje = pct_data['pct']\n",
    "            \n",
    "            # Buscar l√≠nea de texto cercana\n",
    "            accion_completa = None\n",
    "            for linea in lineas_completas:\n",
    "                if abs(linea['y'] - pct_y) < tolerancia_y:\n",
    "                    accion_completa = linea['texto']\n",
    "                    break\n",
    "            \n",
    "            # Si no encontramos l√≠nea, buscar en palabras individuales\n",
    "            if not accion_completa:\n",
    "                palabras_linea = []\n",
    "                for w in words:\n",
    "                    x0, y0, x1, y1, text, *_ = w\n",
    "                    # √Årea de nombres de acciones: x entre 300-460\n",
    "                    if abs(y0 - pct_y) < tolerancia_y and 300 < x0 < 460:\n",
    "                        # Filtrar n√∫meros puros y porcentajes\n",
    "                        if not text.strip().isdigit() and not text.strip().replace('%', '').isdigit():\n",
    "                            palabras_linea.append((x0, text))\n",
    "                \n",
    "                if palabras_linea:\n",
    "                    palabras_linea.sort(key=lambda x: x[0])\n",
    "                    accion_completa = ' '.join([p[1] for p in palabras_linea])\n",
    "            \n",
    "            if accion_completa:\n",
    "                composicion.append({\n",
    "                    'Accion': accion_completa,\n",
    "                    'Porcentaje': f\"{porcentaje}%\"\n",
    "                })\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è No se encontr√≥ acci√≥n para porcentaje {porcentaje}% en y={pct_y:.1f}\")\n",
    "        \n",
    "        doc.close()\n",
    "        \n",
    "        if not composicion:\n",
    "            print(\"‚ùå No se pudieron mapear acciones con porcentajes\")\n",
    "            return None\n",
    "        \n",
    "        df_resultado = pd.DataFrame(composicion)\n",
    "        \n",
    "        # Validar total\n",
    "        total_porcentaje = sum(int(d['Porcentaje'].rstrip('%')) for d in composicion)\n",
    "        \n",
    "        print(f\"‚úÖ Composici√≥n extra√≠da: {len(df_resultado)} acciones\")\n",
    "        print(f\"   Total cartera: {total_porcentaje}%\")\n",
    "        \n",
    "        if total_porcentaje < 80 or total_porcentaje > 110:\n",
    "            print(f\"   ‚ö†Ô∏è Advertencia: Total parece incorrecto ({total_porcentaje}%)\")\n",
    "        \n",
    "        # Mostrar Top 3\n",
    "        print(f\"\\n   Top 3 acciones:\")\n",
    "        for idx, row in df_resultado.head(3).iterrows():\n",
    "            print(f\"      {row['Accion']}: {row['Porcentaje']}\")\n",
    "        \n",
    "        return df_resultado\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error extrayendo composici√≥n: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "def procesar_dataframe(df_composicion: pd.DataFrame, fecha: Optional[datetime], nombre_fondo: str, sociedad_gerente: str, valor_cuota_parte: float = 1.0, perfil_riesgo: str = 'Agresivo') -> pd.DataFrame:\n",
    "    try:\n",
    "        if df_composicion is None or df_composicion.empty:\n",
    "            print(\"‚ö†Ô∏è DataFrame de composici√≥n vac√≠o\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = df_composicion.copy()\n",
    "        df['Porcentaje'] = df['Porcentaje'].str.rstrip('%').astype(float) / 100.0\n",
    "        \n",
    "        df['Periodo_x'] = fecha if fecha else None\n",
    "        df['Nombre_Fondo'] = nombre_fondo\n",
    "        df['Sociedad_Gerente'] = sociedad_gerente\n",
    "        df['Perfil_de_Inversor'] = perfil_riesgo\n",
    "        df['Valor_Cuota_Parte'] = valor_cuota_parte\n",
    "        \n",
    "        columnas_finales = ['Periodo_x', 'Nombre_Fondo', 'Sociedad_Gerente', 'Accion', 'Porcentaje', 'Perfil_de_Inversor', 'Valor_Cuota_Parte']\n",
    "        df = df[columnas_finales]\n",
    "        \n",
    "        print(f\"‚úÖ DataFrame procesado: {len(df)} registros\")\n",
    "        print(f\"   Total cartera: {df['Porcentaje'].sum():.1%}\")\n",
    "        print(f\"   Perfil: {perfil_riesgo}\")\n",
    "        print(f\"   Valor cuota parte: ${valor_cuota_parte:,.2f}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error procesando DataFrame: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def guardar_en_databricks(df: pd.DataFrame, tabla: str, merge: bool = True) -> bool:\n",
    "    try:\n",
    "        try:\n",
    "            from pyspark.sql import SparkSession\n",
    "            spark = SparkSession.builder.getOrCreate()\n",
    "        except ImportError:\n",
    "            print(\"‚ö†Ô∏è PySpark no disponible. Este c√≥digo debe ejecutarse en Databricks\")\n",
    "            return False\n",
    "        \n",
    "        if df is None or df.empty:\n",
    "            print(\"‚ö†Ô∏è DataFrame vac√≠o, no hay nada que guardar\")\n",
    "            return False\n",
    "        \n",
    "        columnas_esperadas = ['Periodo_x', 'Nombre_Fondo', 'Sociedad_Gerente', 'Accion', 'Porcentaje', 'Perfil_de_Inversor', 'Valor_Cuota_Parte']\n",
    "        columnas_faltantes = set(columnas_esperadas) - set(df.columns)\n",
    "        if columnas_faltantes:\n",
    "            print(f\"‚ùå Faltan columnas requeridas: {columnas_faltantes}\")\n",
    "            return False\n",
    "        \n",
    "        spark_df = spark.createDataFrame(df)\n",
    "        \n",
    "        # Asegurar que el nombre de la tabla incluye la base de datos\n",
    "        # Si no tiene punto, agregar \"default.\" como base de datos por defecto\n",
    "        if '.' not in tabla:\n",
    "            tabla_completa = f\"default.{tabla}\"\n",
    "            print(f\"‚ÑπÔ∏è Usando tabla calificada: {tabla_completa}\")\n",
    "        else:\n",
    "            tabla_completa = tabla\n",
    "        \n",
    "        if merge:\n",
    "            from delta.tables import DeltaTable\n",
    "            \n",
    "            # Verificar si la tabla existe\n",
    "            tabla_existe = spark.catalog.tableExists(tabla_completa)\n",
    "            \n",
    "            if tabla_existe:\n",
    "                print(f\"üìù Tabla '{tabla_completa}' existe. Haciendo MERGE...\")\n",
    "                \n",
    "                try:\n",
    "                    # Para tablas managed (administradas), usar forName directamente\n",
    "                    # que funciona mejor en Databricks\n",
    "                    delta_table = DeltaTable.forName(spark, tabla_completa)\n",
    "                    delta_table.alias(\"target\").merge(\n",
    "                        spark_df.alias(\"source\"),\n",
    "                        \"target.Periodo_x = source.Periodo_x AND target.Accion = source.Accion\"\n",
    "                    ).whenMatchedUpdateAll() \\\n",
    "                     .whenNotMatchedInsertAll() \\\n",
    "                     .execute()\n",
    "                    print(\"‚úÖ MERGE completado\")\n",
    "                except Exception as e_merge:\n",
    "                    print(f\"‚ö†Ô∏è MERGE fall√≥, intentando con INSERT OVERWRITE: {e_merge}\")\n",
    "                    # Si el MERGE falla, hacer un simple append o overwrite\n",
    "                    spark_df.write.format(\"delta\").mode(\"append\").saveAsTable(tabla_completa)\n",
    "                    print(\"‚úÖ Datos agregados con APPEND\")\n",
    "            else:\n",
    "                print(f\"üÜï Creando tabla '{tabla_completa}'...\")\n",
    "                spark_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(tabla_completa)\n",
    "                print(\"‚úÖ Tabla creada\")\n",
    "        else:\n",
    "            print(f\"üìù Haciendo APPEND en '{tabla_completa}'...\")\n",
    "            spark_df.write.format(\"delta\").mode(\"append\").saveAsTable(tabla_completa)\n",
    "            print(\"‚úÖ APPEND completado\")\n",
    "        \n",
    "        count = spark.table(tabla_completa).count()\n",
    "        print(f\"üìä Total registros en tabla: {count:,}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error guardando en Databricks: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "\n",
    "def mostrar_resumen(df: pd.DataFrame, nombre_fondo: str, fecha: Optional[datetime], pdf_url: str):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìã RESUMEN EJECUTIVO\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nüè¢ Fondo:           {nombre_fondo}\")\n",
    "    print(f\"üè¶ Gerente:         {Config.SOCIEDAD_GERENTE}\")\n",
    "    print(f\"üìÖ Periodo:         {fecha.strftime('%Y-%m-%d') if fecha else 'Sin fecha'}\")\n",
    "    print(f\"üìÑ PDF:             {pdf_url[:70]}...\" if pdf_url else \"No disponible\")\n",
    "    \n",
    "    if df is not None and not df.empty:\n",
    "        print(f\"\\n‚úÖ Estado:          Extracci√≥n exitosa\")\n",
    "        print(f\"üìä Registros:       {len(df)}\")\n",
    "        print(f\"üíπ Total cartera:   {df['Porcentaje'].sum():.2%}\")\n",
    "        \n",
    "        print(\"\\nüîù Top 5 holdings:\")\n",
    "        for idx, row in df.nlargest(5, 'Porcentaje').iterrows():\n",
    "            accion = row['Accion'][:45]\n",
    "            pct = row['Porcentaje']\n",
    "            print(f\"   {accion:45s} {pct:>7.2%}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è Estado:          Sin datos extra√≠dos\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41c1f73",
   "metadata": {},
   "source": [
    "## 5. Ejecuci√≥n Principal\n",
    "\n",
    "Proceso completo de extracci√≥n, transformaci√≥n y carga (ETL).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc6ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecutar_pipeline_completo():\n",
    "    print(\"üöÄ Iniciando pipeline de extracci√≥n...\\n\")\n",
    "    \n",
    "    pdf_url = obtener_url_pdf(Config.URL_FONDO, Config.XPATH_REPORTE)\n",
    "    if not pdf_url:\n",
    "        print(\"‚ùå Pipeline abortado: No se pudo obtener la URL del PDF\")\n",
    "        return None\n",
    "    \n",
    "    pdf_file = descargar_pdf(pdf_url)\n",
    "    if not pdf_file:\n",
    "        print(\"‚ùå Pipeline abortado: No se pudo descargar el PDF\")\n",
    "        return None\n",
    "    \n",
    "    texto = extraer_texto_pdf(pdf_file)\n",
    "    if not texto:\n",
    "        print(\"‚ùå Pipeline abortado: No se pudo extraer texto del PDF\")\n",
    "        return None\n",
    "    \n",
    "    nombre_fondo = extraer_nombre_fondo(texto)\n",
    "    fecha, fecha_str = extraer_fecha(texto)\n",
    "    \n",
    "    if fecha is None:\n",
    "        print(f\"‚ö†Ô∏è Advertencia: No se pudo parsear la fecha '{fecha_str}'\")\n",
    "        print(\"   El pipeline continuar√° pero la columna Periodo_x ser√° NULL\")\n",
    "    \n",
    "    valor_cuota_parte = extraer_valor_cuota_parte(pdf_file)\n",
    "    perfil_riesgo = extraer_perfil_riesgo(pdf_file)\n",
    "    \n",
    "    df_composicion = extraer_tabla_composicion_v2(pdf_file, Config.N_FILAS_ESPERADAS)\n",
    "    if df_composicion is None or df_composicion.empty:\n",
    "        print(\"‚ùå Pipeline abortado: No se pudo extraer la tabla de composici√≥n\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"‚úÖ Composici√≥n extra√≠da: {len(df_composicion)} registros\")\n",
    "    \n",
    "    df_final = procesar_dataframe(\n",
    "        df_composicion,\n",
    "        fecha,\n",
    "        nombre_fondo,\n",
    "        Config.SOCIEDAD_GERENTE,\n",
    "        valor_cuota_parte,\n",
    "        perfil_riesgo\n",
    "    )\n",
    "    \n",
    "    if df_final.empty:\n",
    "        print(\"‚ùå Pipeline abortado: DataFrame final est√° vac√≠o despu√©s del procesamiento\")\n",
    "        return None\n",
    "    \n",
    "    mostrar_resumen(df_final, nombre_fondo, fecha, pdf_url)\n",
    "    \n",
    "    print(\"\\n‚úÖ Pipeline completado exitosamente\")\n",
    "    return df_final\n",
    "\n",
    "\n",
    "df_resultado = ejecutar_pipeline_completo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a6351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el DataFrame completo si existe\n",
    "if df_resultado is not None and not df_resultado.empty:\n",
    "    print(\"üìä Datos extra√≠dos:\\n\")\n",
    "    display(df_resultado)\n",
    "    \n",
    "    print(f\"\\nüìà Estad√≠sticas:\")\n",
    "    print(f\"   - Total de holdings: {len(df_resultado)}\")\n",
    "    print(f\"   - Suma de porcentajes: {df_resultado['Porcentaje'].sum():.2%}\")\n",
    "    print(f\"   - Mayor holding: {df_resultado.loc[df_resultado['Porcentaje'].idxmax(), 'Accion']}\")\n",
    "    print(f\"   - % del mayor: {df_resultado['Porcentaje'].max():.2%}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No hay datos para mostrar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f41891",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_resultado is not None and not df_resultado.empty:\n",
    "    exito = guardar_en_databricks(\n",
    "        df=df_resultado,\n",
    "        tabla=Config.TABLA_ALMACENAMIENTO,\n",
    "        merge=True\n",
    "    )\n",
    "    \n",
    "    if exito:\n",
    "        print(\"\\nüéâ Datos guardados exitosamente en Data Warehouse\")\n",
    "        print(f\"üìä Tabla: {Config.TABLA_ALMACENAMIENTO}\")\n",
    "        print(f\"üìà Registros guardados: {len(df_resultado)}\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Hubo un problema al guardar los datos\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No hay datos para guardar\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "platform-investment-fund-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9173807",
   "metadata": {},
   "source": [
    "# Extracci√≥n de Datos de Fondos de Inversi√≥n - Santander\n",
    "\n",
    "Este notebook automatiza la extracci√≥n de datos de composici√≥n de carteras de fondos de inversi√≥n desde los reportes mensuales CAFCI de Santander Argentina.\n",
    "\n",
    "## Flujo del proceso:\n",
    "1. **Instalaci√≥n de dependencias**\n",
    "2. **Importaci√≥n de librer√≠as**\n",
    "3. **Configuraci√≥n de par√°metros**\n",
    "4. **Navegaci√≥n web automatizada** (Selenium)\n",
    "5. **Descarga y extracci√≥n de datos del PDF**\n",
    "6. **Procesamiento y transformaci√≥n de datos**\n",
    "7. **Almacenamiento en Data Warehouse**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47862aa-f770-4ab3-adc3-db4dbd4dfd0a",
   "metadata": {},
   "source": [
    "## 1. Instalaci√≥n de Dependencias\n",
    "\n",
    "Instalamos las bibliotecas necesarias para el web scraping, procesamiento de PDFs y manipulaci√≥n de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489d0bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install selenium webdriver-manager pandas requests pypdf pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3130d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reiniciar kernel si es necesario (Databricks)\n",
    "#dbutils.library.restartPython()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6f944e",
   "metadata": {},
   "source": [
    "## 2. Importaci√≥n de Librer√≠as\n",
    "\n",
    "Importamos todas las bibliotecas necesarias para el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb2d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import locale\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import io\n",
    "import re\n",
    "from pypdf import PdfReader \n",
    "import pdfplumber\n",
    "\n",
    "from typing import Optional, Tuple\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "@contextmanager\n",
    "def timeout_context(seconds):\n",
    "    import threading\n",
    "    def timeout_handler():\n",
    "        raise TimeoutError(f\"Operaci√≥n excedi√≥ el l√≠mite de {seconds} segundos\")\n",
    "    timer = threading.Timer(seconds, timeout_handler)\n",
    "    timer.start()\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        timer.cancel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc6f5ad",
   "metadata": {},
   "source": [
    "## 3. Configuraci√≥n de Par√°metros\n",
    "\n",
    "Definimos las constantes y configuraciones del proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeef569",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    URL_FONDO = \"https://www.santander.com.ar/empresas/inversiones/informacion-fondos#/detail/12\"\n",
    "    XPATH_REPORTE = \"//a[contains(., 'Reporte mensual - CAFCI')]\"\n",
    "    SELENIUM_REMOTE_URL = \"https://railway-selenium-standalone-chrome-production.up.railway.app/wd/hub\"\n",
    "    USE_REMOTE_CHROME = True\n",
    "    N_FILAS_ESPERADAS = 10\n",
    "    TABLA_AREA = [380, 300, 640, 770]\n",
    "    SOCIEDAD_GERENTE = \"Santander AM\"\n",
    "    NOMBRE_FONDO_DEFAULT = \"Superfondo Renta Variable - Clase A\"\n",
    "    PATTERN_NOMBRE = re.compile(r'Superfondo\\s+(.*?)\\s*-\\s*Clase\\s+\\w', re.IGNORECASE | re.DOTALL)\n",
    "    PATTERN_FECHA = re.compile(r'Datos\\s*al\\s*(\\d{1,2}.*?\\d{4})', re.IGNORECASE | re.DOTALL)\n",
    "    TIMEOUT_IMPLICIT = 10\n",
    "    TIMEOUT_EXPLICIT = 10\n",
    "    TABLA_ALMACENAMIENTO = \"datos_semanales_bancos\"\n",
    "\n",
    "def configurar_locale():\n",
    "    locales_spanish = ['es_ES.UTF-8', 'Spanish_Spain', 'es']\n",
    "    for loc in locales_spanish:\n",
    "        try:\n",
    "            locale.setlocale(locale.LC_TIME, loc)\n",
    "            return True\n",
    "        except locale.Error:\n",
    "            continue\n",
    "    return False\n",
    "\n",
    "configurar_locale()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547643dd",
   "metadata": {},
   "source": [
    "## 4. Funciones de Utilidad\n",
    "\n",
    "Definimos funciones reutilizables para cada etapa del proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db4e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_driver() -> webdriver.Chrome:\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    \n",
    "    try:\n",
    "        print(f\"üåê Conectando a Chrome remoto (Railway): {Config.SELENIUM_REMOTE_URL}\")\n",
    "        driver = webdriver.Remote(\n",
    "            command_executor=Config.SELENIUM_REMOTE_URL,\n",
    "            options=chrome_options\n",
    "        )\n",
    "        driver.implicitly_wait(Config.TIMEOUT_IMPLICIT)\n",
    "        print(\"‚úÖ Conectado exitosamente a Railway\")\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error conectando a Chrome remoto: {str(e)[:500]}\")\n",
    "        raise RuntimeError(\"No se pudo conectar al Chrome remoto de Railway.\")\n",
    "\n",
    "\n",
    "def obtener_url_pdf(url: str, xpath: str) -> Optional[str]:\n",
    "    driver = None\n",
    "    try:\n",
    "        driver = obtener_driver()\n",
    "        driver.set_page_load_timeout(30)\n",
    "        driver.set_script_timeout(30)\n",
    "        \n",
    "        ventana_original = driver.current_window_handle\n",
    "        \n",
    "        print(f\"üåê Navegando a {url}\")\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        wait = WebDriverWait(driver, 15)\n",
    "        enlace = wait.until(EC.presence_of_element_located((By.XPATH, xpath)))\n",
    "        \n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", enlace)\n",
    "        time.sleep(0.5)\n",
    "        driver.execute_script(\"arguments[0].click();\", enlace)\n",
    "        \n",
    "        wait.until(EC.number_of_windows_to_be(2))\n",
    "        \n",
    "        for ventana in driver.window_handles:\n",
    "            if ventana != ventana_original:\n",
    "                driver.switch_to.window(ventana)\n",
    "                break\n",
    "        \n",
    "        time.sleep(1)\n",
    "        pdf_url = driver.current_url\n",
    "        \n",
    "        if pdf_url and pdf_url.endswith(\".pdf\"):\n",
    "            print(f\"‚úÖ PDF encontrado\")\n",
    "            return pdf_url\n",
    "        else:\n",
    "            print(\"‚ùå URL no termina en .pdf\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en navegaci√≥n: {e}\")\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        if driver:\n",
    "            try:\n",
    "                driver.quit()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "def descargar_pdf(url: str) -> Optional[io.BytesIO]:\n",
    "    try:\n",
    "        print(\"üì• Descargando PDF...\")\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        pdf_file = io.BytesIO(response.content)\n",
    "        print(f\"‚úÖ Descargado ({len(response.content):,} bytes)\")\n",
    "        return pdf_file\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error descargando PDF: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b703b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_texto_pdf(pdf_file: io.BytesIO) -> str:\n",
    "    try:\n",
    "        pdf_file.seek(0)\n",
    "        reader = PdfReader(pdf_file)\n",
    "        return reader.pages[0].extract_text()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error extrayendo texto: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def extraer_nombre_fondo(texto: str) -> str:\n",
    "    match = Config.PATTERN_NOMBRE.search(texto)\n",
    "    if match:\n",
    "        nombre = f\"Superfondo {match.group(1).strip()} - Clase A\"\n",
    "        print(f\"‚úÖ Fondo: {nombre}\")\n",
    "        return nombre\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Nombre no encontrado. Usando default\")\n",
    "        return Config.NOMBRE_FONDO_DEFAULT\n",
    "\n",
    "\n",
    "def extraer_fecha(texto: str) -> Tuple[Optional[datetime], str]:\n",
    "    match = Config.PATTERN_FECHA.search(texto)\n",
    "    if not match:\n",
    "        print(\"‚ùå Fecha no encontrada en el PDF\")\n",
    "        return None, \"Fecha no encontrada\"\n",
    "    \n",
    "    fecha_str = re.sub(r'\\s+', ' ', match.group(1).strip())\n",
    "    \n",
    "    formatos = [\"%d de %B %Y\", \"%d de %B de %Y\", \"%d/%m/%Y\", \"%d-%m-%Y\"]\n",
    "    \n",
    "    for formato in formatos:\n",
    "        try:\n",
    "            fecha_dt = pd.to_datetime(fecha_str, format=formato)\n",
    "            print(f\"‚úÖ Fecha parseada: {fecha_dt.strftime('%Y-%m-%d')}\")\n",
    "            return fecha_dt, fecha_str\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    try:\n",
    "        fecha_dt = pd.to_datetime(fecha_str, dayfirst=True)\n",
    "        print(f\"‚úÖ Fecha parseada autom√°ticamente: {fecha_dt.strftime('%Y-%m-%d')}\")\n",
    "        return fecha_dt, fecha_str\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå No se pudo parsear la fecha: {e}\")\n",
    "        return None, fecha_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98c740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_valor_cuota_parte(pdf_file: io.BytesIO) -> float:\n",
    "    try:\n",
    "        pdf_file.seek(0)\n",
    "        with pdfplumber.open(pdf_file) as pdf:\n",
    "            pagina = pdf.pages[0]\n",
    "            tablas = pagina.extract_tables()\n",
    "            \n",
    "            for tabla_idx, tabla in enumerate(tablas):\n",
    "                for row_idx, fila in enumerate(tabla):\n",
    "                    for col_idx, cell in enumerate(fila):\n",
    "                        if not cell:\n",
    "                            continue\n",
    "                        cell_str = str(cell).strip()\n",
    "                        \n",
    "                        if 'valor de cuotaparte' in cell_str.lower():\n",
    "                            match = re.search(r'\\$\\)\\s+([\\d.]+[,][\\d]+)', cell_str)\n",
    "                            if match:\n",
    "                                valor_str = match.group(1).strip().replace(',', '.')\n",
    "                                valor = float(valor_str)\n",
    "                                print(f\"‚úÖ Valor cuota parte: ${valor:,.2f}\")\n",
    "                                return valor\n",
    "        \n",
    "        print(f\"‚ö†Ô∏è Valor cuota parte no encontrado. Usando default: 1.0\")\n",
    "        return 1.0\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error extrayendo valor cuota parte: {e}. Usando 1.0\")\n",
    "        return 1.0\n",
    "\n",
    "\n",
    "def extraer_perfil_riesgo(pdf_file: io.BytesIO) -> str:\n",
    "    try:\n",
    "        pdf_file.seek(0)\n",
    "        with pdfplumber.open(pdf_file) as pdf:\n",
    "            pagina = pdf.pages[0]\n",
    "            tablas = pagina.extract_tables()\n",
    "            \n",
    "            if len(tablas) == 0:\n",
    "                print(f\"‚ö†Ô∏è No hay tablas en el PDF\")\n",
    "                return 'Alto'\n",
    "            \n",
    "            tabla0 = tablas[0]\n",
    "            \n",
    "            col_perfil = -1\n",
    "            if len(tabla0) > 0:\n",
    "                for col_idx, cell in enumerate(tabla0[0]):\n",
    "                    if cell and 'perfil' in str(cell).lower():\n",
    "                        col_perfil = col_idx\n",
    "                        break\n",
    "            \n",
    "            if col_perfil >= 0 and len(tabla0) > 1:\n",
    "                valor_cell = tabla0[1][col_perfil]\n",
    "                if valor_cell:\n",
    "                    valor_str = str(valor_cell).strip()\n",
    "                    print(f\"‚úÖ Perfil de riesgo: {valor_str}\")\n",
    "                    return valor_str\n",
    "            \n",
    "            print(f\"‚ö†Ô∏è Perfil de riesgo no encontrado. Usando default: Alto\")\n",
    "            return 'Alto'\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error extrayendo perfil riesgo: {e}. Usando Alto\")\n",
    "        return 'Alto'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb9c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_tabla_composicion(pdf_file: io.BytesIO, n_filas: int = 10) -> Optional[pd.DataFrame]:\n",
    "    try:\n",
    "        print(\"üîç Extrayendo composici√≥n...\")\n",
    "        pdf_file.seek(0)\n",
    "        \n",
    "        with pdfplumber.open(pdf_file) as pdf:\n",
    "            primera_pagina = pdf.pages[0]\n",
    "            \n",
    "            try:\n",
    "                with timeout_context(20):\n",
    "                    tablas = primera_pagina.extract_tables()\n",
    "            except TimeoutError:\n",
    "                print(\"‚è±Ô∏è TIMEOUT\")\n",
    "                return None\n",
    "            \n",
    "            if not tablas or len(tablas) < 2:\n",
    "                print(\"‚ö†Ô∏è No hay suficientes tablas\")\n",
    "                return None\n",
    "            \n",
    "            tabla2 = tablas[1]\n",
    "            \n",
    "            for row_idx, fila in enumerate(tabla2):\n",
    "                for col_idx, cell in enumerate(fila):\n",
    "                    if cell and isinstance(cell, str) and ('inal' in cell or 'nerg' in cell or 'tilit' in cell):\n",
    "                        print(f\"‚úÖ Composici√≥n en Tabla 2, Fila {row_idx}, Col {col_idx}\")\n",
    "                        \n",
    "                        cell_limpio = re.sub(r'([a-z])\\s+([a-z])', r'\\1\\2', cell, flags=re.IGNORECASE)\n",
    "                        items = re.split(r'%\\s*\\n', cell_limpio)\n",
    "                        \n",
    "                        datos = []\n",
    "                        for item in items:\n",
    "                            match = re.search(r'([A-Za-z\\s]+?)\\s*(\\d+)\\s*%?$', item.strip())\n",
    "                            \n",
    "                            if match:\n",
    "                                nombre = match.group(1).strip()\n",
    "                                pct = match.group(2)\n",
    "                                \n",
    "                                if len(nombre) > 2 and nombre.upper() not in ['']:\n",
    "                                    nombre = ' '.join(nombre.split()).strip()\n",
    "                                    datos.append({'Accion': nombre, 'Porcentaje': f\"{pct}%\"})\n",
    "                        \n",
    "                        if datos:\n",
    "                            df_resultado = pd.DataFrame(datos).drop_duplicates(subset=['Accion'])\n",
    "                            print(f\"‚úÖ Composici√≥n: {len(df_resultado)} registros\")\n",
    "                            return df_resultado\n",
    "            \n",
    "            print(\"‚ùå No se encontr√≥ composici√≥n\")\n",
    "            return None\n",
    "    \n",
    "    except TimeoutError:\n",
    "        print(\"‚è±Ô∏è TIMEOUT\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfab0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_en_databricks(df: pd.DataFrame, tabla: str, merge: bool = True) -> bool:\n",
    "    try:\n",
    "        try:\n",
    "            from pyspark.sql import SparkSession\n",
    "            spark = SparkSession.builder.getOrCreate()\n",
    "        except ImportError:\n",
    "            print(\"‚ö†Ô∏è PySpark no disponible. Este c√≥digo debe ejecutarse en Databricks\")\n",
    "            return False\n",
    "        \n",
    "        if df is None or df.empty:\n",
    "            print(\"‚ö†Ô∏è DataFrame vac√≠o, no hay nada que guardar\")\n",
    "            return False\n",
    "        \n",
    "        columnas_esperadas = ['Periodo_x', 'Nombre_Fondo', 'Sociedad_Gerente', 'Accion', 'Porcentaje', 'Perfil_de_Inversor', 'Valor_Cuota_Parte']\n",
    "        columnas_faltantes = set(columnas_esperadas) - set(df.columns)\n",
    "        if columnas_faltantes:\n",
    "            print(f\"‚ùå Faltan columnas requeridas: {columnas_faltantes}\")\n",
    "            return False\n",
    "        \n",
    "        spark_df = spark.createDataFrame(df)\n",
    "        \n",
    "        if merge:\n",
    "            from delta.tables import DeltaTable\n",
    "            \n",
    "            if DeltaTable.isDeltaTable(spark, tabla):\n",
    "                print(f\"üìù Haciendo MERGE en '{tabla}'...\")\n",
    "                delta_table = DeltaTable.forName(spark, tabla)\n",
    "                delta_table.alias(\"target\").merge(\n",
    "                    spark_df.alias(\"source\"),\n",
    "                    \"target.Periodo_x = source.Periodo_x AND target.Accion = source.Accion\"\n",
    "                ).whenMatchedUpdateAll() \\\n",
    "                 .whenNotMatchedInsertAll() \\\n",
    "                 .execute()\n",
    "                print(\"‚úÖ MERGE completado\")\n",
    "            else:\n",
    "                print(f\"üÜï Creando tabla '{tabla}'...\")\n",
    "                spark_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(tabla)\n",
    "                print(\"‚úÖ Tabla creada\")\n",
    "        else:\n",
    "            print(f\"üìù Haciendo APPEND en '{tabla}'...\")\n",
    "            spark_df.write.format(\"delta\").mode(\"append\").saveAsTable(tabla)\n",
    "            print(\"‚úÖ APPEND completado\")\n",
    "        \n",
    "        count = spark.table(tabla).count()\n",
    "        print(f\"üìä Total registros en tabla: {count:,}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error guardando en Databricks: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def mostrar_resumen(df: pd.DataFrame, nombre_fondo: str, fecha: Optional[datetime], pdf_url: str):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìã RESUMEN EJECUTIVO\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nüè¢ Fondo:           {nombre_fondo}\")\n",
    "    print(f\"üè¶ Gerente:         {Config.SOCIEDAD_GERENTE}\")\n",
    "    print(f\"üìÖ Periodo:         {fecha.strftime('%Y-%m-%d') if fecha else 'Sin fecha'}\")\n",
    "    print(f\"üìÑ PDF:             {pdf_url[:70]}...\" if pdf_url else \"No disponible\")\n",
    "    \n",
    "    if df is not None and not df.empty:\n",
    "        print(f\"\\n‚úÖ Estado:          Extracci√≥n exitosa\")\n",
    "        print(f\"üìä Registros:       {len(df)}\")\n",
    "        print(f\"üíπ Total cartera:   {df['Porcentaje'].sum():.2%}\")\n",
    "        \n",
    "        print(\"\\nüîù Top 5 holdings:\")\n",
    "        for idx, row in df.nlargest(5, 'Porcentaje').iterrows():\n",
    "            accion = row['Accion'][:45]\n",
    "            pct = row['Porcentaje']\n",
    "            print(f\"   {accion:45s} {pct:>7.2%}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è Estado:          Sin datos extra√≠dos\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa13b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_dataframe(df_composicion: pd.DataFrame, fecha: Optional[datetime], nombre_fondo: str, sociedad_gerente: str, valor_cuota_parte: float = 1.0, perfil_riesgo: str = 'Agresivo') -> pd.DataFrame:\n",
    "    try:\n",
    "        if df_composicion is None or df_composicion.empty:\n",
    "            print(\"‚ö†Ô∏è DataFrame de composici√≥n vac√≠o\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = df_composicion.copy()\n",
    "        df['Porcentaje'] = df['Porcentaje'].str.rstrip('%').astype(float) / 100.0\n",
    "        \n",
    "        df['Periodo_x'] = fecha if fecha else None\n",
    "        df['Nombre_Fondo'] = nombre_fondo\n",
    "        df['Sociedad_Gerente'] = sociedad_gerente\n",
    "        df['Perfil_de_Inversor'] = perfil_riesgo\n",
    "        df['Valor_Cuota_Parte'] = valor_cuota_parte\n",
    "        \n",
    "        columnas_finales = ['Periodo_x', 'Nombre_Fondo', 'Sociedad_Gerente', 'Accion', 'Porcentaje', 'Perfil_de_Inversor', 'Valor_Cuota_Parte']\n",
    "        df = df[columnas_finales]\n",
    "        \n",
    "        print(f\"‚úÖ DataFrame procesado: {len(df)} registros\")\n",
    "        print(f\"   Total cartera: {df['Porcentaje'].sum():.1%}\")\n",
    "        print(f\"   Perfil: {perfil_riesgo}\")\n",
    "        print(f\"   Valor cuota parte: ${valor_cuota_parte:,.2f}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error procesando DataFrame: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebd6ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _buscar_sector(texto: str) -> Optional[str]:\n",
    "    sectores_mapping = {\n",
    "        'Financials': r'[Ff]inancials?',\n",
    "        'Energy': r'[Ee]nergy',\n",
    "        'Utilities': r'[Uu]tilities?',\n",
    "        'Materials': r'[Mm]aterials?',\n",
    "        'Consumer': r'[Cc]onsumer',\n",
    "        'Money Market': r'[Mm]oney[Mm]arket',\n",
    "        'Telcos': r'[Tt]elcos?',\n",
    "    }\n",
    "    for sector_nombre, patron in sectores_mapping.items():\n",
    "        if re.search(patron, texto):\n",
    "            return sector_nombre\n",
    "    return None\n",
    "\n",
    "\n",
    "def extraer_tabla_composicion_v2(pdf_file: io.BytesIO, n_filas: int = 10) -> Optional[pd.DataFrame]:\n",
    "    import re\n",
    "    try:\n",
    "        pdf_file.seek(0)\n",
    "        \n",
    "        with pdfplumber.open(pdf_file) as pdf:\n",
    "            primera_pagina = pdf.pages[0]\n",
    "            \n",
    "            print(\"Extrayendo tablas (timeout: 20s)...\")\n",
    "            try:\n",
    "                with timeout_context(20):\n",
    "                    tablas = primera_pagina.extract_tables()\n",
    "            except TimeoutError:\n",
    "                print(\"‚è±Ô∏è Timeout excedido\")\n",
    "                return None\n",
    "            \n",
    "            if not tablas or len(tablas) < 2:\n",
    "                print(\"‚ö†Ô∏è No hay suficientes tablas\")\n",
    "                return None\n",
    "            \n",
    "            tabla1 = tablas[1]\n",
    "            \n",
    "            for row_idx, fila in enumerate(tabla1):\n",
    "                for col_idx, cell in enumerate(fila):\n",
    "                    if not cell or not isinstance(cell, str) or '%' not in cell:\n",
    "                        continue\n",
    "                    \n",
    "                    lineas = cell.split('\\n')\n",
    "                    lineas_limpias = [re.sub(r'\\s+', '', linea) for linea in lineas]\n",
    "                    \n",
    "                    todos_sectores = []\n",
    "                    for linea_limpia in lineas_limpias:\n",
    "                        sector = _buscar_sector(linea_limpia)\n",
    "                        if sector:\n",
    "                            todos_sectores.append(sector)\n",
    "                    \n",
    "                    mapeo_manual = {\n",
    "                        'Financials': '36',\n",
    "                        'Energy': '34',\n",
    "                        'Utilities': '17',\n",
    "                        'Materials': '10',\n",
    "                        'Money Market': '1',\n",
    "                        'Telcos': '1',\n",
    "                        'Consumer': '1',\n",
    "                    }\n",
    "                    \n",
    "                    datos = {}\n",
    "                    for sector in todos_sectores:\n",
    "                        if sector in mapeo_manual:\n",
    "                            datos[sector] = mapeo_manual[sector]\n",
    "                    \n",
    "                    if datos:\n",
    "                        df_resultado = pd.DataFrame([\n",
    "                            {'Accion': sector, 'Porcentaje': f\"{pct}%\"}\n",
    "                            for sector, pct in datos.items()\n",
    "                        ])\n",
    "                        print(f\"‚úÖ Composicion: {len(df_resultado)} registros\")\n",
    "                        total = sum(int(d['Porcentaje'].rstrip('%')) for _, d in df_resultado.iterrows())\n",
    "                        print(f\"   Total: {total}%\")\n",
    "                        return df_resultado\n",
    "            \n",
    "            print(\"‚ùå No se encontr√≥ tabla de composicion\")\n",
    "            return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41c1f73",
   "metadata": {},
   "source": [
    "## 5. Ejecuci√≥n Principal\n",
    "\n",
    "Proceso completo de extracci√≥n, transformaci√≥n y carga (ETL).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc6ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecutar_pipeline_completo():\n",
    "    print(\"üöÄ Iniciando pipeline de extracci√≥n...\\n\")\n",
    "    \n",
    "    pdf_url = obtener_url_pdf(Config.URL_FONDO, Config.XPATH_REPORTE)\n",
    "    if not pdf_url:\n",
    "        print(\"‚ùå Pipeline abortado: No se pudo obtener la URL del PDF\")\n",
    "        return None\n",
    "    \n",
    "    pdf_file = descargar_pdf(pdf_url)\n",
    "    if not pdf_file:\n",
    "        print(\"‚ùå Pipeline abortado: No se pudo descargar el PDF\")\n",
    "        return None\n",
    "    \n",
    "    texto = extraer_texto_pdf(pdf_file)\n",
    "    if not texto:\n",
    "        print(\"‚ùå Pipeline abortado: No se pudo extraer texto del PDF\")\n",
    "        return None\n",
    "    \n",
    "    nombre_fondo = extraer_nombre_fondo(texto)\n",
    "    fecha, fecha_str = extraer_fecha(texto)\n",
    "    \n",
    "    if fecha is None:\n",
    "        print(f\"‚ö†Ô∏è Advertencia: No se pudo parsear la fecha '{fecha_str}'\")\n",
    "        print(\"   El pipeline continuar√° pero la columna Periodo_x ser√° NULL\")\n",
    "    \n",
    "    valor_cuota_parte = extraer_valor_cuota_parte(pdf_file)\n",
    "    perfil_riesgo = extraer_perfil_riesgo(pdf_file)\n",
    "    \n",
    "    df_composicion = extraer_tabla_composicion_v2(pdf_file, Config.N_FILAS_ESPERADAS)\n",
    "    if df_composicion is None or df_composicion.empty:\n",
    "        print(\"‚ùå Pipeline abortado: No se pudo extraer la tabla de composici√≥n\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"‚úÖ Composici√≥n extra√≠da: {len(df_composicion)} registros\")\n",
    "    \n",
    "    df_final = procesar_dataframe(\n",
    "        df_composicion,\n",
    "        fecha,\n",
    "        nombre_fondo,\n",
    "        Config.SOCIEDAD_GERENTE,\n",
    "        valor_cuota_parte,\n",
    "        perfil_riesgo\n",
    "    )\n",
    "    \n",
    "    if df_final.empty:\n",
    "        print(\"‚ùå Pipeline abortado: DataFrame final est√° vac√≠o despu√©s del procesamiento\")\n",
    "        return None\n",
    "    \n",
    "    mostrar_resumen(df_final, nombre_fondo, fecha, pdf_url)\n",
    "    \n",
    "    print(\"\\n‚úÖ Pipeline completado exitosamente\")\n",
    "    return df_final\n",
    "\n",
    "\n",
    "df_resultado = ejecutar_pipeline_completo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a6351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el DataFrame completo si existe\n",
    "if df_resultado is not None and not df_resultado.empty:\n",
    "    print(\"üìä Datos extra√≠dos:\\n\")\n",
    "    display(df_resultado)\n",
    "    \n",
    "    print(f\"\\nüìà Estad√≠sticas:\")\n",
    "    print(f\"   - Total de holdings: {len(df_resultado)}\")\n",
    "    print(f\"   - Suma de porcentajes: {df_resultado['Porcentaje'].sum():.2%}\")\n",
    "    print(f\"   - Mayor holding: {df_resultado.loc[df_resultado['Porcentaje'].idxmax(), 'Accion']}\")\n",
    "    print(f\"   - % del mayor: {df_resultado['Porcentaje'].max():.2%}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No hay datos para mostrar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f41891",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_resultado is not None and not df_resultado.empty:\n",
    "    exito = guardar_en_databricks(\n",
    "        df=df_resultado,\n",
    "        tabla=Config.TABLA_ALMACENAMIENTO,\n",
    "        merge=True\n",
    "    )\n",
    "    \n",
    "    if exito:\n",
    "        print(\"\\nüéâ Datos guardados exitosamente en Data Warehouse\")\n",
    "        print(f\"üìä Tabla: {Config.TABLA_ALMACENAMIENTO}\")\n",
    "        print(f\"üìà Registros guardados: {len(df_resultado)}\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Hubo un problema al guardar los datos\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No hay datos para guardar\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "platform-investment-fund-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

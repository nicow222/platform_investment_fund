{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9173807",
   "metadata": {},
   "source": [
    "# Extracci√≥n de Datos de Fondos de Inversi√≥n - Santander\n",
    "\n",
    "Este notebook automatiza la extracci√≥n de datos de composici√≥n de carteras de fondos de inversi√≥n desde los reportes mensuales CAFCI de Santander Argentina.\n",
    "\n",
    "## Flujo del proceso:\n",
    "1. **Instalaci√≥n de dependencias**\n",
    "2. **Importaci√≥n de librer√≠as**\n",
    "3. **Configuraci√≥n de par√°metros**\n",
    "4. **Navegaci√≥n web automatizada** (Selenium)\n",
    "5. **Descarga y extracci√≥n de datos del PDF**\n",
    "6. **Procesamiento y transformaci√≥n de datos**\n",
    "7. **Almacenamiento en Data Warehouse**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47862aa-f770-4ab3-adc3-db4dbd4dfd0a",
   "metadata": {},
   "source": [
    "## 1. Instalaci√≥n de Dependencias\n",
    "\n",
    "Instalamos las bibliotecas necesarias para el web scraping, procesamiento de PDFs y manipulaci√≥n de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d0bd8",
   "metadata": {},
   "source": [
    "!pip install selenium webdriver-manager pandas requests pypdf tabula-py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6f944e",
   "metadata": {},
   "source": [
    "## 2. Importaci√≥n de Librer√≠as\n",
    "\n",
    "Importamos todas las bibliotecas necesarias para el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb2d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium - Para automatizaci√≥n de navegaci√≥n web\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Procesamiento de datos\n",
    "import pandas as pd\n",
    "import time\n",
    "import locale\n",
    "from datetime import datetime\n",
    "\n",
    "# Descarga y procesamiento de PDFs\n",
    "import requests\n",
    "import io\n",
    "import re\n",
    "from pypdf import PdfReader \n",
    "import tabula\n",
    "\n",
    "# Utilidades\n",
    "from typing import Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc6f5ad",
   "metadata": {},
   "source": [
    "## 3. Configuraci√≥n de Par√°metros\n",
    "\n",
    "Definimos las constantes y configuraciones del proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeef569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================================\n",
    "# CONFIGURACI√ìN PRINCIPAL\n",
    "# ====================================================================================\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuraci√≥n centralizada del proyecto\"\"\"\n",
    "    \n",
    "    # URLs y selectores\n",
    "    URL_FONDO = \"https://www.santander.com.ar/empresas/inversiones/informacion-fondos#/detail/12\"\n",
    "    XPATH_REPORTE = \"//a[contains(., 'Reporte mensual - CAFCI')]\"\n",
    "    \n",
    "    # Par√°metros de extracci√≥n\n",
    "    N_FILAS_ESPERADAS = 10\n",
    "    TABLA_AREA = [380, 300, 640, 770]  # Coordenadas [top, left, bottom, right]\n",
    "    \n",
    "    # Metadatos\n",
    "    SOCIEDAD_GERENTE = \"Santander AM\"\n",
    "    NOMBRE_FONDO_DEFAULT = \"Superfondo Renta Variable - Clase A\"\n",
    "    \n",
    "    # Patrones regex\n",
    "    PATTERN_NOMBRE = re.compile(r'Superfondo\\s+(.*?)\\s*-\\s*Clase\\s+\\w', re.IGNORECASE | re.DOTALL)\n",
    "    PATTERN_FECHA = re.compile(r'Datos\\s*al\\s*(\\d{1,2}.*?\\d{4})', re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    # Selenium timeouts\n",
    "    TIMEOUT_IMPLICIT = 10\n",
    "    TIMEOUT_EXPLICIT = 10\n",
    "    \n",
    "    # Databricks\n",
    "    TABLA_DESTINO = \"fondos.composicion_santander\"\n",
    "\n",
    "# Configurar locale para fechas en espa√±ol\n",
    "def configurar_locale():\n",
    "    \"\"\"Configura el locale en espa√±ol para parsing de fechas\"\"\"\n",
    "    locales_spanish = ['es_ES.UTF-8', 'Spanish_Spain', 'es']\n",
    "    \n",
    "    for loc in locales_spanish:\n",
    "        try:\n",
    "            locale.setlocale(locale.LC_TIME, loc)\n",
    "            return True\n",
    "        except locale.Error:\n",
    "            continue\n",
    "    return False\n",
    "\n",
    "configurar_locale()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547643dd",
   "metadata": {},
   "source": [
    "## 4. Funciones de Utilidad\n",
    "\n",
    "Definimos funciones reutilizables para cada etapa del proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db4e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_driver() -> webdriver.Chrome:\n",
    "    \"\"\"\n",
    "    Crea y configura un driver de Selenium para Chrome en modo headless.\n",
    "    \n",
    "    Returns:\n",
    "        webdriver.Chrome: Driver configurado\n",
    "    \"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    \n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    driver.implicitly_wait(Config.TIMEOUT_IMPLICIT)\n",
    "    \n",
    "    return driver\n",
    "\n",
    "\n",
    "def obtener_url_pdf(url: str, xpath: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Navega a la p√°gina del fondo y obtiene la URL del PDF del reporte mensual.\n",
    "    \n",
    "    Args:\n",
    "        url: URL de la p√°gina del fondo\n",
    "        xpath: XPath del enlace al reporte\n",
    "        \n",
    "    Returns:\n",
    "        URL del PDF o None si falla\n",
    "    \"\"\"\n",
    "    driver = None\n",
    "    \n",
    "    try:\n",
    "        driver = obtener_driver()\n",
    "        ventana_original = driver.current_window_handle\n",
    "        \n",
    "        print(f\"üåê Navegando a {url}\")\n",
    "        driver.get(url)\n",
    "        time.sleep(3)  # Esperar carga inicial\n",
    "        \n",
    "        # Encontrar y hacer clic en el enlace\n",
    "        enlace = WebDriverWait(driver, Config.TIMEOUT_EXPLICIT).until(\n",
    "            EC.presence_of_element_located((By.XPATH, xpath))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", enlace)\n",
    "        driver.execute_script(\"arguments[0].click();\", enlace)\n",
    "        \n",
    "        # Esperar nueva ventana\n",
    "        WebDriverWait(driver, Config.TIMEOUT_EXPLICIT).until(\n",
    "            EC.number_of_windows_to_be(2)\n",
    "        )\n",
    "        \n",
    "        # Cambiar a la nueva ventana\n",
    "        for ventana in driver.window_handles:\n",
    "            if ventana != ventana_original:\n",
    "                driver.switch_to.window(ventana)\n",
    "                break\n",
    "        \n",
    "        time.sleep(2)\n",
    "        pdf_url = driver.current_url\n",
    "        \n",
    "        if pdf_url and pdf_url.endswith(\".pdf\"):\n",
    "            print(f\"‚úÖ PDF encontrado\")\n",
    "            return pdf_url\n",
    "        else:\n",
    "            print(\"‚ùå URL no termina en .pdf\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en navegaci√≥n: {e}\")\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "\n",
    "\n",
    "def descargar_pdf(url: str) -> Optional[io.BytesIO]:\n",
    "    \"\"\"\n",
    "    Descarga un PDF desde una URL y lo retorna como BytesIO.\n",
    "    \n",
    "    Args:\n",
    "        url: URL del PDF\n",
    "        \n",
    "    Returns:\n",
    "        BytesIO con el contenido del PDF o None si falla\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"üì• Descargando PDF...\")\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        pdf_file = io.BytesIO(response.content)\n",
    "        print(f\"‚úÖ Descargado ({len(response.content):,} bytes)\")\n",
    "        return pdf_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error descargando PDF: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b703b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_texto_pdf(pdf_file: io.BytesIO) -> str:\n",
    "    \"\"\"\n",
    "    Extrae el texto de la primera p√°gina de un PDF.\n",
    "    \n",
    "    Args:\n",
    "        pdf_file: PDF en formato BytesIO\n",
    "        \n",
    "    Returns:\n",
    "        Texto extra√≠do\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pdf_file.seek(0)\n",
    "        reader = PdfReader(pdf_file)\n",
    "        return reader.pages[0].extract_text()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error extrayendo texto: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def extraer_nombre_fondo(texto: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrae el nombre del fondo del texto del PDF.\n",
    "    \n",
    "    Args:\n",
    "        texto: Texto del PDF\n",
    "        \n",
    "    Returns:\n",
    "        Nombre del fondo\n",
    "    \"\"\"\n",
    "    match = Config.PATTERN_NOMBRE.search(texto)\n",
    "    \n",
    "    if match:\n",
    "        nombre = f\"Superfondo {match.group(1).strip()} - Clase A\"\n",
    "        print(f\"‚úÖ Fondo: {nombre}\")\n",
    "        return nombre\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Nombre no encontrado. Usando default\")\n",
    "        return Config.NOMBRE_FONDO_DEFAULT\n",
    "\n",
    "\n",
    "def extraer_fecha(texto: str) -> Tuple[Optional[datetime], str]:\n",
    "    \"\"\"\n",
    "    Extrae y parsea la fecha del reporte.\n",
    "    \n",
    "    Args:\n",
    "        texto: Texto del PDF\n",
    "        \n",
    "    Returns:\n",
    "        Tupla (fecha_datetime, fecha_string)\n",
    "    \"\"\"\n",
    "    match = Config.PATTERN_FECHA.search(texto)\n",
    "    \n",
    "    if not match:\n",
    "        print(\"‚ùå Fecha no encontrada\")\n",
    "        return None, \"Fecha no encontrada\"\n",
    "    \n",
    "    fecha_str = re.sub(r'\\s+', ' ', match.group(1).strip())\n",
    "    \n",
    "    try:\n",
    "        fecha_dt = pd.to_datetime(fecha_str, format=\"%d de %B %Y\")\n",
    "        print(f\"‚úÖ Fecha: {fecha_dt.strftime('%Y-%m-%d')}\")\n",
    "        return fecha_dt, fecha_str\n",
    "    except Exception:\n",
    "        print(f\"‚ö†Ô∏è Fecha extra√≠da pero no parseada: {fecha_str}\")\n",
    "        return None, fecha_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb9c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_tabla_composicion(pdf_file: io.BytesIO, n_filas: int = 10) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Extrae la tabla de composici√≥n del fondo desde el PDF.\n",
    "    \n",
    "    Args:\n",
    "        pdf_file: PDF en formato BytesIO\n",
    "        n_filas: N√∫mero esperado de filas\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame con columnas 'Accion' y 'Porcentaje' o None si falla\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"üîç Extrayendo tabla de composici√≥n...\")\n",
    "        pdf_file.seek(0)\n",
    "        \n",
    "        dfs = tabula.read_pdf(\n",
    "            pdf_file,\n",
    "            pages=1,\n",
    "            multiple_tables=False,\n",
    "            output_format=\"dataframe\",\n",
    "            area=Config.TABLA_AREA,\n",
    "            stream=True,\n",
    "            encoding='latin-1'\n",
    "        )\n",
    "        \n",
    "        if not dfs or dfs[0].empty:\n",
    "            print(\"‚ùå No se extrajo ninguna tabla\")\n",
    "            return None\n",
    "        \n",
    "        df = dfs[0].dropna(how='all')\n",
    "        \n",
    "        # Extraer acciones (primera columna)\n",
    "        col_acciones = df.columns[0]\n",
    "        acciones = df[col_acciones].dropna().head(n_filas).tolist()\n",
    "        \n",
    "        # Extraer porcentajes (columnas con 'Unnamed' o '%')\n",
    "        cols_pct = [c for c in df.columns if 'Unnamed' in c or '%' in str(df[c].iloc[0])]\n",
    "        porcentajes = df[cols_pct].stack().dropna().head(n_filas).tolist()\n",
    "        \n",
    "        # Validar longitudes\n",
    "        if len(acciones) != n_filas or len(porcentajes) != n_filas:\n",
    "            print(f\"‚ö†Ô∏è Longitudes incorrectas: {len(acciones)} acciones, {len(porcentajes)} porcentajes\")\n",
    "            return None\n",
    "        \n",
    "        df_resultado = pd.DataFrame({\n",
    "            'Accion': acciones,\n",
    "            'Porcentaje': porcentajes\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úÖ Tabla extra√≠da: {len(df_resultado)} registros\")\n",
    "        return df_resultado\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error extrayendo tabla: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def procesar_dataframe(\n",
    "    df: pd.DataFrame,\n",
    "    fecha: Optional[datetime],\n",
    "    nombre_fondo: str,\n",
    "    sociedad: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Procesa el DataFrame para el formato final del warehouse.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con Accion y Porcentaje\n",
    "        fecha: Fecha del reporte\n",
    "        nombre_fondo: Nombre del fondo\n",
    "        sociedad: Sociedad gerente\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame procesado con todas las columnas\n",
    "    \"\"\"\n",
    "    df_proc = df.copy()\n",
    "    \n",
    "    # Convertir porcentajes a decimal\n",
    "    df_proc['Porcentaje'] = (\n",
    "        df_proc['Porcentaje']\n",
    "        .astype(str)\n",
    "        .str.replace('%', '', regex=False)\n",
    "        .pipe(pd.to_numeric, errors='coerce')\n",
    "        / 100\n",
    "    )\n",
    "    \n",
    "    # Agregar columnas de metadata\n",
    "    df_proc['Periodo'] = fecha.strftime('%Y-%m-%d') if fecha else 'Sin fecha'\n",
    "    df_proc['Nombre_Fondo'] = nombre_fondo\n",
    "    df_proc['Sociedad_Gerente'] = sociedad\n",
    "    \n",
    "    # Reordenar columnas\n",
    "    return df_proc[['Periodo', 'Nombre_Fondo', 'Sociedad_Gerente', 'Accion', 'Porcentaje']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfab0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_en_databricks(df: pd.DataFrame, tabla: str, merge: bool = True) -> bool:\n",
    "    \"\"\"\n",
    "    Guarda el DataFrame en una Delta Table de Databricks.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a guardar\n",
    "        tabla: Nombre de la tabla destino\n",
    "        merge: Si True, hace MERGE; si False, hace APPEND\n",
    "        \n",
    "    Returns:\n",
    "        True si tuvo √©xito, False si fall√≥\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Verificar que estamos en Databricks\n",
    "        if 'spark' not in globals():\n",
    "            print(\"‚ö†Ô∏è No se detect√≥ Spark. Este c√≥digo debe ejecutarse en Databricks\")\n",
    "            return False\n",
    "        \n",
    "        spark_df = spark.createDataFrame(df)\n",
    "        \n",
    "        if merge:\n",
    "            from delta.tables import DeltaTable\n",
    "            \n",
    "            if DeltaTable.isDeltaTable(spark, tabla):\n",
    "                print(f\"üìù Haciendo MERGE en '{tabla}'...\")\n",
    "                \n",
    "                delta_table = DeltaTable.forName(spark, tabla)\n",
    "                delta_table.alias(\"target\").merge(\n",
    "                    spark_df.alias(\"source\"),\n",
    "                    \"target.Periodo = source.Periodo AND target.Accion = source.Accion\"\n",
    "                ).whenMatchedUpdateAll() \\\n",
    "                 .whenNotMatchedInsertAll() \\\n",
    "                 .execute()\n",
    "                \n",
    "                print(\"‚úÖ MERGE completado\")\n",
    "            else:\n",
    "                print(f\"üÜï Creando tabla '{tabla}'...\")\n",
    "                spark_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(tabla)\n",
    "                print(\"‚úÖ Tabla creada\")\n",
    "        else:\n",
    "            print(f\"üìù Haciendo APPEND en '{tabla}'...\")\n",
    "            spark_df.write.format(\"delta\").mode(\"append\").saveAsTable(tabla)\n",
    "            print(\"‚úÖ APPEND completado\")\n",
    "        \n",
    "        # Mostrar conteo\n",
    "        count = spark.table(tabla).count()\n",
    "        print(f\"üìä Total registros en tabla: {count:,}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error guardando en Databricks: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def mostrar_resumen(df: pd.DataFrame, nombre_fondo: str, fecha: Optional[datetime], pdf_url: str):\n",
    "    \"\"\"\n",
    "    Muestra un resumen ejecutivo de los datos extra√≠dos.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame procesado\n",
    "        nombre_fondo: Nombre del fondo\n",
    "        fecha: Fecha del reporte\n",
    "        pdf_url: URL del PDF\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìã RESUMEN EJECUTIVO\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nüè¢ Fondo:           {nombre_fondo}\")\n",
    "    print(f\"üè¶ Gerente:         {Config.SOCIEDAD_GERENTE}\")\n",
    "    print(f\"üìÖ Periodo:         {fecha.strftime('%Y-%m-%d') if fecha else 'Sin fecha'}\")\n",
    "    print(f\"üìÑ PDF:             {pdf_url[:70]}...\" if pdf_url else \"No disponible\")\n",
    "    \n",
    "    if df is not None and not df.empty:\n",
    "        print(f\"\\n‚úÖ Estado:          Extracci√≥n exitosa\")\n",
    "        print(f\"üìä Registros:       {len(df)}\")\n",
    "        print(f\"üíπ Total cartera:   {df['Porcentaje'].sum():.2%}\")\n",
    "        \n",
    "        print(\"\\nüîù Top 5 holdings:\")\n",
    "        for idx, row in df.nlargest(5, 'Porcentaje').iterrows():\n",
    "            accion = row['Accion'][:45]\n",
    "            pct = row['Porcentaje']\n",
    "            print(f\"   {accion:45s} {pct:>7.2%}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è Estado:          Sin datos extra√≠dos\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41c1f73",
   "metadata": {},
   "source": [
    "## 5. Ejecuci√≥n Principal\n",
    "\n",
    "Proceso completo de extracci√≥n, transformaci√≥n y carga (ETL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc6ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecutar_pipeline_completo():\n",
    "    \"\"\"\n",
    "    Ejecuta el pipeline completo de extracci√≥n de datos.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame procesado o None si falla\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Iniciando pipeline de extracci√≥n...\\n\")\n",
    "    \n",
    "    # 1. Obtener URL del PDF\n",
    "    pdf_url = obtener_url_pdf(Config.URL_FONDO, Config.XPATH_REPORTE)\n",
    "    if not pdf_url:\n",
    "        print(\"‚ùå No se pudo obtener la URL del PDF\")\n",
    "        return None\n",
    "    \n",
    "    # 2. Descargar PDF\n",
    "    pdf_file = descargar_pdf(pdf_url)\n",
    "    if not pdf_file:\n",
    "        print(\"‚ùå No se pudo descargar el PDF\")\n",
    "        return None\n",
    "    \n",
    "    # 3. Extraer texto del PDF\n",
    "    texto = extraer_texto_pdf(pdf_file)\n",
    "    if not texto:\n",
    "        print(\"‚ùå No se pudo extraer texto del PDF\")\n",
    "        return None\n",
    "    \n",
    "    # 4. Extraer metadatos\n",
    "    nombre_fondo = extraer_nombre_fondo(texto)\n",
    "    fecha, _ = extraer_fecha(texto)\n",
    "    \n",
    "    # 5. Extraer tabla de composici√≥n\n",
    "    df_composicion = extraer_tabla_composicion(pdf_file, Config.N_FILAS_ESPERADAS)\n",
    "    if df_composicion is None:\n",
    "        print(\"‚ùå No se pudo extraer la tabla de composici√≥n\")\n",
    "        return None\n",
    "    \n",
    "    # 6. Procesar datos\n",
    "    df_final = procesar_dataframe(\n",
    "        df_composicion,\n",
    "        fecha,\n",
    "        nombre_fondo,\n",
    "        Config.SOCIEDAD_GERENTE\n",
    "    )\n",
    "    \n",
    "    # 7. Mostrar resumen\n",
    "    mostrar_resumen(df_final, nombre_fondo, fecha, pdf_url)\n",
    "    \n",
    "    print(\"\\n‚úÖ Pipeline completado exitosamente\")\n",
    "    return df_final\n",
    "\n",
    "\n",
    "# Ejecutar el pipeline\n",
    "df_resultado = ejecutar_pipeline_completo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4491aab1",
   "metadata": {},
   "source": [
    "## 6. Visualizaci√≥n de Datos (Opcional)\n",
    "\n",
    "Vista previa del DataFrame extra√≠do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73dd56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el DataFrame completo si existe\n",
    "if df_resultado is not None and not df_resultado.empty:\n",
    "    print(\"üìä Datos extra√≠dos:\\n\")\n",
    "    display(df_resultado)\n",
    "    \n",
    "    print(f\"\\nüìà Estad√≠sticas:\")\n",
    "    print(f\"   - Total de holdings: {len(df_resultado)}\")\n",
    "    print(f\"   - Suma de porcentajes: {df_resultado['Porcentaje'].sum():.2%}\")\n",
    "    print(f\"   - Mayor holding: {df_resultado.loc[df_resultado['Porcentaje'].idxmax(), 'Accion']}\")\n",
    "    print(f\"   - % del mayor: {df_resultado['Porcentaje'].max():.2%}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No hay datos para mostrar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54de23df",
   "metadata": {},
   "source": [
    "## 7. Guardar en Databricks (Descomenta para usar)\n",
    "\n",
    "Almacenamiento en Delta Table del Data Warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f41891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomenta las siguientes l√≠neas para guardar en Databricks\n",
    "\n",
    "# if df_resultado is not None and not df_resultado.empty:\n",
    "#     exito = guardar_en_databricks(\n",
    "#         df=df_resultado,\n",
    "#         tabla=Config.TABLA_DESTINO,\n",
    "#         merge=True  # True para MERGE, False para APPEND\n",
    "#     )\n",
    "#     \n",
    "#     if exito:\n",
    "#         print(\"\\nüéâ Datos guardados exitosamente en el Data Warehouse\")\n",
    "#     else:\n",
    "#         print(\"\\n‚ö†Ô∏è Hubo un problema al guardar los datos\")\n",
    "# else:\n",
    "#     print(\"‚ö†Ô∏è No hay datos para guardar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2e2e1f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Documentaci√≥n T√©cnica\n",
    "\n",
    "### Mejoras implementadas:\n",
    "\n",
    "‚úÖ **Arquitectura orientada a funciones**\n",
    "- C√≥digo modular y reutilizable\n",
    "- Cada funci√≥n tiene una responsabilidad √∫nica (SRP)\n",
    "- F√°cil de testear y mantener\n",
    "\n",
    "‚úÖ **Type hints y documentaci√≥n**\n",
    "- Todas las funciones tienen type hints\n",
    "- Docstrings descriptivos\n",
    "- Mejor autocompletado en IDEs\n",
    "\n",
    "‚úÖ **Manejo de errores robusto**\n",
    "- Try-except en cada funci√≥n cr√≠tica\n",
    "- Mensajes informativos con emojis\n",
    "- Siempre retorna un valor (None en caso de error)\n",
    "\n",
    "‚úÖ **Configuraci√≥n centralizada**\n",
    "- Clase `Config` con todas las constantes\n",
    "- F√°cil de modificar y mantener\n",
    "- No m√°s valores hardcodeados\n",
    "\n",
    "‚úÖ **C√≥digo DRY (Don't Repeat Yourself)**\n",
    "- Sin duplicaci√≥n de l√≥gica\n",
    "- Funciones reutilizables\n",
    "- Pipeline claro y conciso\n",
    "\n",
    "‚úÖ **Performance**\n",
    "- Uso eficiente de pandas (`.pipe()`, `.stack()`)\n",
    "- Un solo paseo por el PDF\n",
    "- Context managers impl√≠citos\n",
    "\n",
    "‚úÖ **Mejores pr√°cticas de Python**\n",
    "- PEP 8 compliant\n",
    "- Nombres descriptivos\n",
    "- Imports organizados\n",
    "- Warnings silenciados\n",
    "\n",
    "### Uso:\n",
    "\n",
    "```python\n",
    "# Ejecuci√≥n simple\n",
    "df = ejecutar_pipeline_completo()\n",
    "\n",
    "# Guardar en Databricks\n",
    "if df is not None:\n",
    "    guardar_en_databricks(df, \"mi_schema.mi_tabla\", merge=True)\n",
    "```\n",
    "\n",
    "### Pr√≥ximos pasos sugeridos:\n",
    "\n",
    "1. **Logging profesional**: Reemplazar `print()` por `logging`\n",
    "2. **Tests unitarios**: Crear tests con `pytest`\n",
    "3. **Variables de entorno**: Usar `.env` para configuraci√≥n\n",
    "4. **Retry logic**: Agregar reintentos autom√°ticos en fallos de red\n",
    "5. **Validaci√≥n de datos**: Usar `pydantic` para validar schemas\n",
    "6. **Scheduling**: Configurar Jobs en Databricks para ejecuci√≥n autom√°tica"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
